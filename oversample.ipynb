{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "im_count = df[df.Id != 'new_whale'].Id.value_counts()\n",
    "im_count.name = 'sighting_count'\n",
    "df = df.join(im_count, on='Id')\n",
    "#Validation set is the first sighting of every whale with >1 sightings\n",
    "val_fns = set(df.sample(frac=1)[(df.Id != 'new_whale') & (df.sighting_count > 1)].groupby('Id').first().Image)\n",
    "#KL: There are 5004 whales (not counting new_whale) and 2073 whales with one sighting,\n",
    "#so there should be 5004-2073=2931 whales in the validation set\n",
    "print(len(val_fns))\n",
    "#KL: this line saves your validation set for everything else to use\n",
    "pd.to_pickle(val_fns, 'data/val_fns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.073000e+03,   1.285000e+03,   5.680000e+02,   2.730000e+02, ...,   0.000000e+00,   0.000000e+00,\n",
       "          0.000000e+00,   1.000000e+00]),\n",
       " array([ 1,  2,  3,  4, ..., 70, 71, 72, 73]),\n",
       " <a list of 72 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd8204b8d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KL: Plot showing how many whales there are (y axis) with a given number of sightings (x axis)\n",
    "#KL: For instance, there are 2073 whales with one sighting, 1285 whales with two sightings\n",
    "#KL: The whale with the most sightings has 73\n",
    "plt.hist(im_count,range(1,74),log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(val_fns, 'data/val_fns')\n",
    "val_fns = pd.read_pickle('data/val_fns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 8\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Id != 'new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15697, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sighting_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df.Image.isin(val_fns)]\n",
    "df_train = df[~df.Image.isin(val_fns)]\n",
    "df_train_with_val = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2931, 3), (12766, 3), (15697, 3))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape, df_train.shape, df_train_with_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 4 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = None\n",
    "#KL: Original resampled training data keeps all whales with > 15 sightings and adds duplicates of all whales with < 15 \n",
    "#sightings to bring the sighting count up to 15. The result is mostly evenly sampled training data, with any whale with\n",
    "#>15 sightings over-represented\n",
    "sample_to = 15\n",
    "\n",
    "for grp in df_train.groupby('Id'):\n",
    "    n = grp[1].shape[0]\n",
    "    additional_rows = grp[1].sample(0 if sample_to < n  else sample_to - n, replace=True)\n",
    "    rows = pd.concat((grp[1], additional_rows))\n",
    "    \n",
    "    if res is None: res = rows\n",
    "    else: res = pd.concat((res, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 0 ns, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res_with_val = None\n",
    "#KL: Original resampled training data keeps all whales with > 15 sightings and adds duplicates of all whales with < 15 \n",
    "#sightings to bring the sighting count up to 15. The result is mostly evenly sampled training data, with any whale with\n",
    "#>15 sightings over-represented\n",
    "sample_to = 15\n",
    "\n",
    "for grp in df_train_with_val.groupby('Id'):\n",
    "    n = grp[1].shape[0]\n",
    "    additional_rows = grp[1].sample(0 if sample_to < n  else sample_to - n, replace=True)\n",
    "    rows = pd.concat((grp[1], additional_rows))\n",
    "    \n",
    "    if res_with_val is None: res_with_val = rows\n",
    "    else: res_with_val = pd.concat((res_with_val, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76174, 3), (76287, 3))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, res_with_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set increased 6-fold, but that is still an amount of data that is okay. I don't think it makes sense to worry about breaking up the data into smaller epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((res, df_val))[['Image', 'Id']].to_csv('data/oversampled_train.csv', index=False)\n",
    "res_with_val[['Image', 'Id']].to_csv('data/oversampled_train_and_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naming here is not very fortunate, but the idea is that `oversampled_train` has single entries for images in `val_fns` and `oversampled_train_and_val` is both `val` and `train` combined. Meaning, `oversampled_train_and_val` is one we might want to use when retraining on the entire train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/oversampled_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], 'data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('data/test'))\n",
    "        .transform(get_transforms(do_flip=False, max_zoom=1, max_warp=0, max_rotate=2), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (76174 items)\n",
       "[Category w_0003639, Category w_0003639, Category w_0003639, Category w_0003639, Category w_0003639]...\n",
       "Path: data/train\n",
       "x: ImageItemList (76174 items)\n",
       "[Image (3, 700, 1050), Image (3, 700, 1050), Image (3, 700, 1050), Image (3, 700, 1050), Image (3, 700, 1050)]...\n",
       "Path: data/train;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (2931 items)\n",
       "[Category w_c3d896a, Category w_20df2c5, Category w_64404ac, Category w_a6f9d33, Category w_d3b46e7]...\n",
       "Path: data/train\n",
       "x: ImageItemList (2931 items)\n",
       "[Image (3, 325, 758), Image (3, 497, 1050), Image (3, 450, 1050), Image (3, 667, 1000), Image (3, 347, 1050)]...\n",
       "Path: data/train;\n",
       "\n",
       "Test: LabelList\n",
       "y: CategoryList (7960 items)\n",
       "[Category w_0003639, Category w_0003639, Category w_0003639, Category w_0003639, Category w_0003639]...\n",
       "Path: data/train\n",
       "x: ImageItemList (7960 items)\n",
       "[Image (3, 321, 562), Image (3, 333, 1050), Image (3, 600, 1050), Image (3, 372, 1050), Image (3, 405, 630)]...\n",
       "Path: data/train"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
